{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5cd12-c222-4973-af55-8a931bf2bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2dfe02-5504-41c2-ab6d-3da197da04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_EVALUATION_SUMMARY_PATH = \"/veld/input/\" + os.getenv(\"in_evaluation_summary_file\")\n",
    "OUT_VISUALIZATION_HTML_PATH = \"/veld/output/\" + os.getenv(\"out_visualization_html_file\")\n",
    "OUT_VISUALIZATION_PNG_PATH = \"/veld/output/\" + os.getenv(\"out_visualization_png_file\")\n",
    "print(f\"IN_EVALUATION_SUMMARY_PATH: {IN_EVALUATION_SUMMARY_PATH}\")\n",
    "print(f\"OUT_VISUALIZATION_HTML_PATH: {OUT_VISUALIZATION_HTML_PATH}\")\n",
    "print(f\"OUT_VISUALIZATION_PNG_PATH: {OUT_VISUALIZATION_PNG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ea3df-5a79-4ea1-b6cb-e5d961e94856",
   "metadata": {},
   "source": [
    "# load summary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b4149-1376-442f-be19-4c099e43641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(IN_EVALUATION_SUMMARY_PATH, \"r\") as file_in:\n",
    "    eval_summary_raw = file_in.read()\n",
    "    print(eval_summary_raw)\n",
    "    eval_summary = yaml.safe_load(eval_summary_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579003e9-d79b-40e8-bc85-7ebfe121eb43",
   "metadata": {},
   "source": [
    "# transform to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669ed76-8fa2-4b1b-ba84-5ae3caa2acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_summary_data():\n",
    "    \n",
    "    def normalize_size(size_str):\n",
    "        if size_str.endswith(\"G\"):\n",
    "            return float(size_str[:-1])\n",
    "        elif size_str.endswith(\"M\"):\n",
    "            return float(size_str[:-1]) / 1000\n",
    "        else:\n",
    "            raise Exception\n",
    "    \n",
    "    def normalize_epochs(model_id_details_dict):\n",
    "        if \"training_epochs\" in model_id_details_dict:\n",
    "            return int(model_id_details_dict[\"training_epochs\"])\n",
    "        elif \"max_iter\" in model_id_details_dict:\n",
    "            return int(model_id_details_dict[\"max_iter\"])\n",
    "        else:\n",
    "            raise Exception\n",
    "    \n",
    "    def normalize_vectors(model_id_details_dict):\n",
    "        if \"vector_size\" in model_id_details_dict:\n",
    "            return int(model_id_details_dict[\"vector_size\"])\n",
    "        elif \"training_vector_size\" in model_id_details_dict:\n",
    "            return int(model_id_details_dict[\"training_vector_size\"])\n",
    "        else:\n",
    "            raise Exception\n",
    "    \n",
    "    def normalize_min_count(model_id_details_dict):\n",
    "        if \"vocab_min_count\" in model_id_details_dict:\n",
    "            return int(model_id_details_dict[\"vocab_min_count\"])\n",
    "        elif \"min_count\" in model_id_details_dict:\n",
    "            return int(model_id_details_dict[\"min_count\"])\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def load_summary_data_main():\n",
    "            df = pd.DataFrame()\n",
    "            for model_arch, model_arch_dict in eval_summary.items():\n",
    "                model_arch_noramlized = model_arch[:1]\n",
    "                for model_id, model_id_dict in model_arch_dict.items():\n",
    "                    model_id_details_dict = model_id_dict[\"model_details\"]\n",
    "                    model_id_score_dict = model_id_dict[\"score\"]\n",
    "                    df_tmp = pd.DataFrame(\n",
    "                        {\n",
    "                            \"model id\": [model_arch_noramlized + model_id[-1]],\n",
    "                            \"score synonyms\": [model_id_score_dict[\"synonyms\"]],\n",
    "                            \"score homonyms\": [model_id_score_dict[\"homonyms\"]],\n",
    "                            \"score antonyms\": [model_id_score_dict[\"antonyms\"]],\n",
    "                            \"vector size\": normalize_vectors(model_id_details_dict),\n",
    "                            \"min word count\": normalize_min_count(model_id_details_dict),\n",
    "                            \"training epochs\": normalize_epochs(model_id_details_dict),\n",
    "                            \"training duration (hours)\": int(model_id_details_dict[\"training_duration (minutes)\"] / 60),\n",
    "                            \"model data size (GB)\": [normalize_size(model_id_details_dict[\"model_data_size\"])],\n",
    "                            \"train data size (GB)\": [normalize_size(model_id_details_dict[\"train_data_size\"])],\n",
    "                            \"train data hash\": model_id_details_dict[\"train_data_md5_hash\"][:8],\n",
    "                        }\n",
    "                    )\n",
    "                    df = pd.concat([df, df_tmp], ignore_index=True)\n",
    "            return df\n",
    "\n",
    "    return load_summary_data_main()\n",
    "    \n",
    "df = load_summary_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a9f80-ad1b-46b3-9dd4-c450f8123c83",
   "metadata": {},
   "source": [
    "# transform for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006286c-3e5b-445c-bd70-80a4317207fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dimensions(df):\n",
    "    \n",
    "    def create_axis(df, col_name):\n",
    "    \n",
    "        # check if this column has any non-numeric value\n",
    "        is_numeric = True\n",
    "        for row in df.iterrows():\n",
    "            row_list = row[1].to_list()\n",
    "            try:\n",
    "                round(row_list[1], 3)\n",
    "            except:\n",
    "                is_numeric = False\n",
    "                break\n",
    "    \n",
    "        # iterate over rows and create potentially compressed value-label pairs\n",
    "        value_list = []\n",
    "        ticks_dict = {}\n",
    "        non_numeric_dict = {}\n",
    "        for row in df.iterrows():\n",
    "    \n",
    "            # get label and value from row\n",
    "            row_list = row[1].to_list()\n",
    "            label = row_list[0]\n",
    "            value = row_list[1]\n",
    "            try:\n",
    "                value = round(value, 3)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "            # merge labels if values already occurred before\n",
    "            label_pre = ticks_dict.get(value)\n",
    "            if label_pre is not None:\n",
    "                label = label_pre + \",\" + label\n",
    "            ticks_dict[value] = label\n",
    "    \n",
    "            # handle non-numeric values, by creating fake numeric values\n",
    "            if is_numeric:\n",
    "                value_list.append(value)\n",
    "            else:\n",
    "                fake_value = non_numeric_dict.get(value)\n",
    "                if fake_value is None:\n",
    "                    fake_value = len(non_numeric_dict) + 1\n",
    "                non_numeric_dict[value] = fake_value\n",
    "                value_list.append(fake_value)\n",
    "    \n",
    "        # create main label and value data structure for plotly's tick attributes\n",
    "        tick_label_list = []\n",
    "        tick_value_list = []\n",
    "        for value, label in ticks_dict.items():\n",
    "            value_str = str(value)\n",
    "            if value_str == \"-1\":\n",
    "                value_str = \"null\"\n",
    "            tick_label_list.append(label + \": \" + value_str)\n",
    "            if is_numeric:\n",
    "                tick_value_list.append(value)\n",
    "            else:\n",
    "                tick_value_list.append(non_numeric_dict[value])\n",
    "            \n",
    "        return {\n",
    "            \"tickvals\": tick_value_list,\n",
    "            \"ticktext\": tick_label_list,\n",
    "            \"label\": col_name,\n",
    "            \"values\": value_list,\n",
    "        }\n",
    "\n",
    "    def create_dimensions_main():\n",
    "        dim_list = []\n",
    "        for col_name in df:\n",
    "            if col_name != \"model id\":\n",
    "                dim_list.append(create_axis(df[[\"model id\", col_name]], col_name))\n",
    "        return dim_list\n",
    "\n",
    "    return create_dimensions_main()\n",
    "    \n",
    "dim_list = create_dimensions(df)\n",
    "dim_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a3b06e-166f-4619-8e00-22edccea54b3",
   "metadata": {},
   "source": [
    "# visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1411459-fc90-45c2-910b-a4de6613ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data=go.Parcoords(\n",
    "        line={\"color\": list(df.index), \"colorscale\": 'Rainbow'},\n",
    "        dimensions=dim_list\n",
    "    )\n",
    ")\n",
    "fig.update_layout(height=700)\n",
    "fig.show()\n",
    "fig.write_html(OUT_VISUALIZATION_HTML_PATH)\n",
    "fig.write_image(OUT_VISUALIZATION_PNG_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
